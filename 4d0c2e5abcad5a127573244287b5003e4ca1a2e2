{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "5ca5a128_08670333",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 7
      },
      "lineNbr": 0,
      "author": {
        "id": 5002
      },
      "writtenOn": "2024-05-16T23:52:05Z",
      "side": 1,
      "message": "We are getting close Mark.",
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6c261fb4_d52515cc",
        "filename": "internal/ceres/generate_bundle_adjustment_tests.py",
        "patchSetId": 7
      },
      "lineNbr": 226,
      "author": {
        "id": 5002
      },
      "writtenOn": "2024-05-16T23:52:05Z",
      "side": 1,
      "message": "I think with cholesky on GPU you have also enabled the ability to do visibility based preconditioning on the GPU.  Can you try ITERATIVE_SCHUR + CLUSTER_JACOBI using bundle_adjuster? I am pretty sure it will work. It may not work well (because of the per iteration back and forth with the GPU) but I think it will work.\n\nIf that is the case, then we need to make two more changes.\n\n1. update \n\n\nITERATIVE_SOLVER_CONFIGS \u003d [\n    # Linear solver            Sparse backend      Preconditioner\n    (\u0027ITERATIVE_SCHUR\u0027,        \u0027NO_SPARSE\u0027,        \u0027JACOBI\u0027),\n    (\u0027ITERATIVE_SCHUR\u0027,        \u0027NO_SPARSE\u0027,        \u0027SCHUR_JACOBI\u0027),\n    (\u0027ITERATIVE_SCHUR\u0027,        \u0027NO_SPARSE\u0027,        \u0027SCHUR_POWER_SERIES_EXPANSION\u0027),\n    (\u0027ITERATIVE_SCHUR\u0027,        \u0027SUITE_SPARSE\u0027,     \u0027CLUSTER_JACOBI\u0027),\n    (\u0027ITERATIVE_SCHUR\u0027,        \u0027EIGEN_SPARSE\u0027,     \u0027CLUSTER_JACOBI\u0027),\n    (\u0027ITERATIVE_SCHUR\u0027,        \u0027ACCELERATE_SPARSE\u0027,\u0027CLUSTER_JACOBI\u0027),\n    (\u0027ITERATIVE_SCHUR\u0027,        \u0027SUITE_SPARSE\u0027,     \u0027CLUSTER_TRIDIAGONAL\u0027),\n    (\u0027ITERATIVE_SCHUR\u0027,        \u0027EIGEN_SPARSE\u0027,     \u0027CLUSTER_TRIDIAGONAL\u0027),\n    (\u0027ITERATIVE_SCHUR\u0027,        \u0027ACCELERATE_SPARSE\u0027,\u0027CLUSTER_TRIDIAGONAL\u0027),\n]\n\nto include CUDA_SPARSE\n\nand this nested if will also need to check for iterative_schur + either of these two preconditioners.",
      "range": {
        "startLine": 226,
        "startChar": 25,
        "endLine": 226,
        "endChar": 37
      },
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0e296444_b73ae23a",
        "filename": "internal/ceres/generate_bundle_adjustment_tests.py",
        "patchSetId": 7
      },
      "lineNbr": 226,
      "author": {
        "id": 6667
      },
      "writtenOn": "2024-05-17T19:17:53Z",
      "side": 1,
      "message": "While it is indeed working via bundle_adjuster (no errors and final cost is close to the suite_sparse variant), it seems to be not stable (based on differences in \"cost_change\") and following tests are failing:\n        125 - ba_iterschur_cudasparse_clusttri_auto_test (Failed)\n        147 - ba_iterschur_cudasparse_clusttri_auto_threads_test (Failed)\n        169 - ba_iterschur_cudasparse_clusttri_user_test (Failed)\n        191 - ba_iterschur_cudasparse_clusttri_user_threads_test (Failed)\n\nStill, i pushed the change and i will try to find some time for digging into that tomorrow.",
      "parentUuid": "6c261fb4_d52515cc",
      "range": {
        "startLine": 226,
        "startChar": 25,
        "endLine": 226,
        "endChar": 37
      },
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "89654b4a_0de69292",
        "filename": "internal/ceres/generate_bundle_adjustment_tests.py",
        "patchSetId": 7
      },
      "lineNbr": 226,
      "author": {
        "id": 5002
      },
      "writtenOn": "2024-05-17T20:41:50Z",
      "side": 1,
      "message": "Thanks, this is interesting. If you can share logs of your experiments maybe I can help debug this too (I do not have a cuda machine setup to do these experiments, but I suppose I should find a vm with cuda hardware).",
      "parentUuid": "0e296444_b73ae23a",
      "range": {
        "startLine": 226,
        "startChar": 25,
        "endLine": 226,
        "endChar": 37
      },
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "de745c97_eafbc82c",
        "filename": "internal/ceres/generate_bundle_adjustment_tests.py",
        "patchSetId": 7
      },
      "lineNbr": 226,
      "author": {
        "id": 6667
      },
      "writtenOn": "2024-05-23T00:57:00Z",
      "side": 1,
      "message": "Focusing on ba_iterschur_cudasparse_clusttri_auto_test i checked that initial lhs\u0026rhs that three solvers in comparation are receiving are identical. I compared the solutions returned by solvers: Eigen\u0027s LDLT returns the most accurate one (7.8859e-03 norm of error), SuiteSparse returns something that results to an error of 93.878 and cuDSS returns vector of NaNs. Even if SuiteSparse returned quite bad \"solution\", it still lets the outer loop to continue and eventually to pass the test, while this is not the case for cuDSS.\n\nThe reason for such behavior is that lhs matrix of a system to be solved is not positive definite (its min eigenvalue is -2.8296e-03), but cuDSS, being configured to assume positive definite lhs, computes LLT instead of LDLT. Changing the type of cuDSS wrapper over lhs to indicate that it is only symmetric leads to cuDSS returning a solution that is almost identical to Eigen\u0027s and to test being passed.\n\nIt seems that proper solution for that issue would be on the side of producer of such matrices, to ensure that Cholesky solver is not receiving such matrices (not really sure if that is possible given presence of numerical errors). If not, then we could unconditionally configure cuDSS to assume only symmetry and always compute LDLT (with a cost of slowdown of about 1.3, measured on that particular test example). Another option would be to, conditioned on initial solution being NaN, try to solve with LDLT, paying more in \"bad\" cases.\n\nWhat would be your suggestion?",
      "parentUuid": "89654b4a_0de69292",
      "range": {
        "startLine": 226,
        "startChar": 25,
        "endLine": 226,
        "endChar": 37
      },
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "464f32f3_47f3c695",
        "filename": "internal/ceres/generate_bundle_adjustment_tests.py",
        "patchSetId": 7
      },
      "lineNbr": 226,
      "author": {
        "id": 5002
      },
      "writtenOn": "2024-05-23T15:54:01Z",
      "side": 1,
      "message": "Hi Mark,\nVery nice debugging.\n\nI am going to assume that you had a good eigenvalue solver and that the indefiniteness of the preconditioner is real. \n\nwhen you say that cudss returns nans, do you mean that when we call solve on the factorized preconditioner matrix and CG iterates we get nans starting with the very first call?\n\nIn that case isn\u0027t the problem that the LLT factorization failed and cuDSS did not tell us that it failed? as in the following line should return failure no? \n\n```\nCUDSS_STATUS_OK_OR_RETURN_SOLVER_ERROR(\n        cudssExecute(context_-\u003ecudss_handle_,\n                     CUDSS_PHASE_FACTORIZATION,\n                     solver_config_,\n                     solver_data_,\n                     cudss_lhs_,\n                     cudss_x_,\n                     cudss_rhs_),\n        \"cudssExecute with CUDSS_PHASE_FACTORIZATION failed\");\n\n    return factorize_result_ \u003d LinearSolverTerminationType::SUCCESS;\n  }\n```\n\nwhich should get propagated up to the implicit_schur_complement_solver as a failed preconditioner update (line 114 of implicit_schur_complement_solver.cc).\n\nAvoiding such matrices at construction time is a bit hard, because bundle adjustment problems are fundamentally poorly conditioned. But cluster-tridiagonal is actually a bit more special. It is expected that sometimes the first call to factorize may fail, See \n\nhttps://github.com/ceres-solver/ceres-solver/blob/master/internal/ceres/visibility_based_preconditioner.cc#L351\n\nwhere if the factorization fails, we rescale the offdiagonal blocks to make the matrix more diagonally dominant and thus more positive definite. \n\nSo its important that cuDSS actually detect the first failure correctly. \n\nso my question here is, is it the first factorization thats failing silently, or the second one? and in that case shouldn\u0027t we treat this as a cuDSS bug?",
      "parentUuid": "de745c97_eafbc82c",
      "range": {
        "startLine": 226,
        "startChar": 25,
        "endLine": 226,
        "endChar": 37
      },
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4e87e38c_0dbcc914",
        "filename": "internal/ceres/generate_bundle_adjustment_tests.py",
        "patchSetId": 7
      },
      "lineNbr": 226,
      "author": {
        "id": 6667
      },
      "writtenOn": "2024-05-23T22:06:13Z",
      "side": 1,
      "message": "\u003e I am going to assume that you had a good eigenvalue solver and that the indefiniteness of the preconditioner is real. \n\nEigen\u0027s SelfAdjointEigenSolver (https://gitlab.com/libeigen/eigen/-/blob/master/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h?ref_type\u003dheads#L199) and octave\u0027s eig() seems to agree on the value.\n\n\u003e when you say that cudss returns nans, do you mean that when we call solve on the factorized preconditioner matrix and CG iterates we get nans starting with the very first call?\n\nYes, i\u0027v logged all the lhs, rhs and solutions that are consumed/produced by an instance of SparseCholesky and the issue appears at the very first factorization/solve iteration in cuDSS case.\n\n\u003e In that case isn\u0027t the problem that the LLT factorization failed and \ncuDSS did not tell us that it failed? as in the following line should \nreturn failure no? \n\nNot quite, given that call to cudssExecute() is non-blocking. I assume, that CUDSS_STATUS_SUCCESS, that is indeed returned from such call, means the success of work scheduling, not the absence of numerical errors encountered during the computation which is actually performed on device while Factorize already returned success to its caller. And i don\u0027t see any methods in cuDSS API to check if factorization scheduled via call to cudssExecute(..., CUDSS_PHASE_FACTORIZATION, ...) is finished without numerical issues. It would be nice if Kirill or Di could verify if such behavior is by design and no relevant changes are to be expected. \n\nAssuming that atm there is no option to check quality of cuDSS factorization prior to solve, i\u0027ve added diagonal scaling and factorization to the VisibilityBasedPreconditioner::RightMultiplyAndAccumulate() in case if failure detected based on explicit check for solution being finite in case of CUDA_SPARSE and CLUSTER_TRIDIAGONAL.",
      "parentUuid": "464f32f3_47f3c695",
      "range": {
        "startLine": 226,
        "startChar": 25,
        "endLine": 226,
        "endChar": 37
      },
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "81b63d75_d8ad6267",
        "filename": "internal/ceres/generate_bundle_adjustment_tests.py",
        "patchSetId": 7
      },
      "lineNbr": 226,
      "author": {
        "id": 5002
      },
      "writtenOn": "2024-05-23T23:33:56Z",
      "side": 1,
      "message": "I had forgotten that the call to cudssExecute is non-blocking. \n\nThat raises a number of questions.\n\n1. The current line 208 of cuda_sparse_cholesky.cc is not correct, because it is signaling that the factorization succeeded, when it is just the scheduling.\n\n2. How do you know that the factorization has finished before calling solve? in line 222? is it because all the operations are being sent on the same cuda stream and they are executed in order in the stream? \n\n3. Forgive my ignorance here, but then how does the call to CopyToCpu work? as in how does it know that the solve has actually finished before it copies the data to the CPU? is there a lock somewhere which blocks this call waiting for CUDSS_PHASE_SOLVE to finish before you copy the data to the cpu memory? otherwise there would be a race condition no?\n\n4. If these calls are non-blocking, then cuDSS API should absolutely have a way of checking for both checking that the operation is done, and what the state of the operation is before further operations can be scheduled no?",
      "parentUuid": "4e87e38c_0dbcc914",
      "range": {
        "startLine": 226,
        "startChar": 25,
        "endLine": 226,
        "endChar": 37
      },
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "555b7507_5dff1307",
        "filename": "internal/ceres/generate_bundle_adjustment_tests.py",
        "patchSetId": 7
      },
      "lineNbr": 226,
      "author": {
        "id": 5002
      },
      "writtenOn": "2024-05-23T23:36:41Z",
      "side": 1,
      "message": "perhaps this offers a clue, the cudssget and set api is to be used for getting runtime errors?\n\nhttps://github.com/NVIDIA/CUDALibrarySamples/blob/master/cuDSS/get_set/get_set.cpp#L279",
      "parentUuid": "81b63d75_d8ad6267",
      "range": {
        "startLine": 226,
        "startChar": 25,
        "endLine": 226,
        "endChar": 37
      },
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ac8fc8ed_e4091b28",
        "filename": "internal/ceres/generated_bundle_adjustment_tests/ba_sparsecholesky_cudasparse_auto_test.cc",
        "patchSetId": 7
      },
      "lineNbr": 43,
      "author": {
        "id": 5002
      },
      "writtenOn": "2024-05-16T23:52:05Z",
      "side": 1,
      "message": "at the risk of creating work for you, but in the interest of consistency these two macros should have the same polarity. \n\nIf we stick with CERES_NO_CUDA then CERES_NO_CUDSS is what we should do no?",
      "range": {
        "startLine": 43,
        "startChar": 7,
        "endLine": 43,
        "endChar": 22
      },
      "fixSuggestions": [
        {
          "fixId": "388f325d_7496fe06",
          "description": "prompt_to_edit API",
          "replacements": [
            {
              "path": "internal/ceres/generated_bundle_adjustment_tests/ba_sparsecholesky_cudasparse_auto_test.cc",
              "range": {
                "startLine": 43,
                "startChar": 0,
                "endLine": 44,
                "endChar": 0
              },
              "replacement": "#ifndef CERES_USE_CUDSS\n"
            }
          ]
        }
      ],
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "6c8eed3c_3a371d65",
        "filename": "internal/ceres/generated_bundle_adjustment_tests/ba_sparsecholesky_cudasparse_auto_test.cc",
        "patchSetId": 7
      },
      "lineNbr": 43,
      "author": {
        "id": 6667
      },
      "writtenOn": "2024-05-17T19:17:53Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "ac8fc8ed_e4091b28",
      "range": {
        "startLine": 43,
        "startChar": 7,
        "endLine": 43,
        "endChar": 22
      },
      "revId": "4d0c2e5abcad5a127573244287b5003e4ca1a2e2",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    }
  ]
}