{
  "comments": [
    {
      "key": {
        "uuid": "f09c7530_0d2705e0",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6372
      },
      "writtenOn": "2020-08-03T11:43:34Z",
      "side": 1,
      "message": "Sorry for hijacking this discussion. As a potential user, I really appreciate this functionality and want to add a little comment regarding the API.\n\nIt would be great to have access to the resulting linear sub-system. The reason is: a linear cost function is the standard way to represent the sub-system, but for things like Quaternions it might be better to do this as manifold operation. With access to the resulting sub-system, everyone could choose whether to use the provided linear cost function or to create a custom one.\nMaybe this could be achieved by exposing one of the lower level functions?",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "e19735c9_7e4867aa",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 5002
      },
      "writtenOn": "2020-08-04T20:43:11Z",
      "side": 1,
      "message": "Tim, did you have an API in mind?",
      "parentUuid": "f09c7530_0d2705e0",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "10f21a72_7af31ba3",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6372
      },
      "writtenOn": "2020-08-05T09:38:29Z",
      "side": 1,
      "message": "I could imagine two different approaches, the fist one requires only minimal changes:\n\n1.a) MarginalizeOutVariables() returns the ResidualBlockId of the new linear cost function.\n1.b) LinearCostFunction() has a getter for its jacobian and linear residual(b).\n\u003d\u003e This would allow the user to get the involved parameter blocks (using the ResidualBlockId) as well as the linear subsystem. It would be possible to remove the LinearCostFunction and replace it with a custom one.\n\nThe second approach would be more involved:\n2.a) MarginalizeOutVariables() doesn\u0027t add the LinearCostFunction to the problem at all. Instead, it returns jacobian, linear residual and the parameter blocks of the markov blanket. Maybe also their sizes for convenience.\n2.b) It is up to the user to add the new LinearCostFunction.\n2.c) The current MarginalizeOutVariables() function becomes MarginalizeOutVariablesAndAddCost().\n\u003d\u003e The user would have the explicit choice whether to use a custom cost function or the provided one.\n\nTo be honest, I\u0027m not sure how many user will use a custom cost function. I would use it in some cases, but the majority might be totally fine with the provided one. So I slightly prefer the first solution -- it has a cleaner interface.\nReturning the ResidualBlockId for the new cost function should done anyway, otherwise it would be impossible to remove it explicitly from the problem.",
      "parentUuid": "e19735c9_7e4867aa",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "fb745263_969570c5",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6372
      },
      "writtenOn": "2020-08-05T14:37:55Z",
      "side": 1,
      "message": "\u003e Patch Set 4:\n\u003e \n\u003e Tim,\n\u003e \n\u003e Is the presence of the manifold the only reason to do this? if so, shouldn\u0027t the margnialization function account for the presence of the manifold instead of the user having to do this?\n\u003e \n\u003e Sameer\n\nHi Sameer,\n\nit is at least the only reason that I\u0027m aware off.\n\nI think an \"ideal\" marginalization should care about manifolds. But this requires to implement a box-minus operator for each local parameterization in order to construct the correct cost function.\nSince the number of blocks of this function can vary at runtime, autodiff isn\u0027t a good option. So Jacobians are also required for this operator.\n\nIt is possible, but exhaustive to do it for the general case. It would also raise the burden of writing new local parameterizations, because everyone would have to implement an additional minus operator.\nOn the other hand it is relatively easy to do for a specific case, where only one ore two local parametrizations are involved.\n\nAdditionally, marginalization is a linear approximation anyway. So it seems acceptable to do this further approximation for the cost function.\nHowever, an interface to represent it exactly would be nice. :-)\n\nBest Regards\nTim",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "6fc5a7ac_be3b049b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6297
      },
      "writtenOn": "2020-08-05T17:30:38Z",
      "side": 1,
      "message": "I think we are clear on the following point, but I just want to say explicitly that the marginalization prior is on the global coordinates of the Markov blanket, it is integrating out the marginalized variables wrt their local coordinates. Integrating out in overparameterized global coordinates would of course neglect information and is not appropriate for manifolds.\n\nAs I see it, the primary choice in the formulation is whether to compute the prior on the global coordinates or local coordinates of the Markov blanket variables. I have seen both approaches taken, but the former is a bit simpler for the reasons Tim noted. I\u0027m not sure in what cases the latter would be preferred? It may be possible to approximate ominus using the pseudoinverse of the Jacobian of the parameterization, but that may not be ideal.",
      "parentUuid": "fb745263_969570c5",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "02ff32ad_914c568d",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6372
      },
      "writtenOn": "2020-08-06T09:22:48Z",
      "side": 1,
      "message": "You are totally right Evan, I have written too vague about this point. The marginalization itself takes care of the manifolds. I was just thinking about the prior which is constructed afterwards.\n\nI guess, the manifold prior might be more accurate in cases where the variable is moved further away from its linearization point.\nA simple example I could imagine is a angular variable wrapped to +-pi. If the linearization point is close to pi and the variable is -pi, a linear prior would have a large residual while the residual on the manifold is small. Similar things could happen for other representations of rotations.",
      "parentUuid": "6fc5a7ac_be3b049b",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "0ac8c6ca_1f0238b2",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6297
      },
      "writtenOn": "2020-08-06T17:10:27Z",
      "side": 1,
      "message": "Tim, thanks for clarifying and the input. Very interested to understand a bit better. Maybe I am still missing a subtlety you have in mind, but I do believe the unit circle / rotation example would be handled appropriately:\n\nLet\u0027s say the manifold here is the unit circle in R2 and the Markov blanket variable takes a value on this manifold. Applying this CR, the mean of the marginalization prior computed on the Markov blanket could be, say, (-1, 0) as it is represented in global coordinates, so that values near +/- pi have small residuals. Note that the CR does not represent the Markov blanket in any local coordinate system. This CR should come up with a linear cost function like [1,0] * ([x,y] - [-1, 0])^T.\n\nLet\u0027s take the same example and interpret the angular variable as the variable to marginalize out. +-pi represents the case where it is moving far from its linearization point, and then all bets are off. Note that in marginalization, we represent the variables to marginalize out as a delta (local coordinates) from some linearization point, which is on the manifold, and we minimize wrt this delta. We require that the minimizer of this delta be small.\n\nThe alternative I had in mind was to compute a linear constraint on the delta (local coordinates) of the Markov blanket from some linearization point determined at the time of marginalization. I guess I don\u0027t see a strong motivation for doing this instead, and as you point out, it involves ominus.",
      "parentUuid": "02ff32ad_914c568d",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "16465be2_1e0edac2",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6372
      },
      "writtenOn": "2020-08-07T08:09:09Z",
      "side": 1,
      "message": "Evan, you are right, for the unit circle it would be handled appropriately.\n\nI had something different in mind when I was thinking about an angular variable:\nhttps://github.com/ceres-solver/ceres-solver/blob/master/examples/slam/pose_graph_2d/angle_local_parameterization.h\n\nIt also represents a rotation, but local and global coordinates are in almost the same space. However, small differences in local coordinates can lead to big differences in the global space. For example: Assume a linearization around pi. The linear cost function would be 1*(phi - pi) with phi as optimized variable.\nAfter a small positive optimization step on phi, its value would be somewhere close to -pi, because it got wrapped by the local param. Now the linear cost is about 2*pi while the actual distance in local coordinates is rather small.\n\nHowever, one could argue that the angle local parametrization might not be the best choice to represent rotation in 2D.\nI think that the linear cost can be problematic for all local parametrization whose global coordinates are not in a euclidean space. Quaternion are another example, two quaternions that are close in the local space could be far apart in the global space.\n\nFinally, I have to admit that my understanding of manifold algebra is quite limited. So please tell me if I missing something.",
      "parentUuid": "0ac8c6ca_1f0238b2",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "0984ec3b_ae6aaa45",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6297
      },
      "writtenOn": "2020-08-08T23:31:37Z",
      "side": 1,
      "message": "Tim, thanks for sharing this, and it\u0027s clear to me now. Roughly, this method requires that the curvature of the global parameterization wrt local is small for the Markov blanket variables. As you said, global coordinates should locally resemble a Euclidean space. Viewed another way, suppose we are doing linear least squares with the identity parameterization, where marginalization works perfectly. If we then reparameterize the variables, this prior can be arbitrarily \"bad\" depending on the curvature of the parameterization.\n\nI will make these points explicit in marginalization.h and that the parameterizations should be chosen judiciously for optimal performance (e.g. SO(3)).\n\nI think the CR is useful for many of the common cases. If the user must use a highly nonlinear parameterization, maybe the options are 1) accept suboptimal accuracy, 2) change the parameterization just before marginalization, 3) further manipulate the linear equations on a case-by-case basis. Enabling Ceres to compute the prior on local coordinates would require handling ominus and more cumbersome expressions. The API choice seems to me like a tradeoff between simplicity and covering these cases.",
      "parentUuid": "16465be2_1e0edac2",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da0eb28c_aa4bd1bc",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6372
      },
      "writtenOn": "2020-08-09T09:56:22Z",
      "side": 1,
      "message": "Evan, thanks for your patience and understanding. I have to correct my former statement about the quaternion parametrization. The unit quaternions should behave much more like your unit ring example. I\u0027m not sure whether these unit quaternions are restricted to a positive real part or not, otherwise the symmetry q and -q could be crucial.\nThe R3 equivalent of my angle example would be Euler angles, which are a bad choice anyway.\n\nAnyway... I agree with you, your work will be extremely useful for the vast majority of applications, including mine. Thanks for that! :-)\n\nI just would like to suggest again two subtle changes of the API:\n1) MarginalizeOutVariables() could return he ResidualBlockId of the new cost function. This would be consistent with Problem::AddResidualBlock and give the user the possibility to remove the cost function if required.\nIn case of failure it could return the nullptr.\n\n2) If LinearCostFunction() has a getter function for its jacobian and linear residual(b), the user would be able to access the linear subsystem and do whatever might be required to handle a special case.",
      "parentUuid": "0984ec3b_ae6aaa45",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "474200eb_7ed6cf12",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6297
      },
      "writtenOn": "2020-08-09T17:50:17Z",
      "side": 1,
      "message": "Good points. I suppose one should choose a parameterization that avoids the -q/q symmetry. There is a comment in the iSAM code that they do not usually use quaternions in the GLCs...\n\nThank you for these great suggestions regarding API. I think these changes would keep it simple and support the use cases we discussed.",
      "parentUuid": "da0eb28c_aa4bd1bc",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "40091f1d_fa8dcbd5",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 4
      },
      "lineNbr": 0,
      "author": {
        "id": 6297
      },
      "writtenOn": "2020-08-11T02:57:38Z",
      "side": 1,
      "message": "I just pushed another patch set to address the points we discussed about API and considerations for use.",
      "parentUuid": "474200eb_7ed6cf12",
      "revId": "e3aa45bd8d7501036d3a17e10f655600d4617601",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329",
      "unresolved": false
    }
  ]
}