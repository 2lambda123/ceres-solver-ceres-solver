{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "8ea9c5dc_86c24492",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 5135
      },
      "writtenOn": "2022-09-14T01:55:45Z",
      "side": 1,
      "message": "Okay, cleaned up.",
      "revId": "8a1a925df1d6b5754a35e6a6a19c255ce2b89991",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "4b01d726_df5a8699",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-14T08:25:49Z",
      "side": 1,
      "message": "This version works fine, while the previous is consistently failing in  CUDADenseCholeskyMixedPrecision.Cholesky4x4Matrix1Step when run with cuda-memcheck\n\nDo you experience the same behavior (in terms of previous version failing when being run with cuda-memcheck)?\n\n\n\n\nI would like to share some thoughts I got after making a thread on google groups.\n\na. Previous version without stream sync in CopyToCpu only fails under cuda-memcheck with tool memcheck; but does not fail without cuda-memcheck or with tools racecheck/synccheck/initcheck. No errors reported by any of these tools, even when test is failing.\n\nb. I find the wording in nvidia docs about implicit synchronization a bit vague - I am still not sure if \"legacy\" behavior is turned on or off by default (but going  stream-synchronous is better in both cases from my point).",
      "revId": "8a1a925df1d6b5754a35e6a6a19c255ce2b89991",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "54887f78_88ab0dd1",
        "filename": "internal/ceres/cuda_buffer.h",
        "patchSetId": 2
      },
      "lineNbr": 113,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-14T02:24:58Z",
      "side": 1,
      "message": "isn\u0027t it important that the same stream be passed here that is used at construction time? should the stream be a constructor argument?",
      "range": {
        "startLine": 113,
        "startChar": 7,
        "endLine": 113,
        "endChar": 16
      },
      "revId": "8a1a925df1d6b5754a35e6a6a19c255ce2b89991",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ef021648_911e34f9",
        "filename": "internal/ceres/cuda_buffer.h",
        "patchSetId": 2
      },
      "lineNbr": 113,
      "author": {
        "id": 5135
      },
      "writtenOn": "2022-09-14T02:42:51Z",
      "side": 1,
      "message": "Technically no, it needs to be whichever stream we should wait on for operations to complete. That said, all Ceres CUDA operations are on the same stream currently so we could just take a stream in the constructor. Let me think about it.\nI also noticed elsewhere that we are inconsistently saving a ContextImpl some places and saving some specific handles from the context in others. Maybe we should just save the contextimpl everywhere so that we are sure all handles and streams are the same.",
      "parentUuid": "54887f78_88ab0dd1",
      "range": {
        "startLine": 113,
        "startChar": 7,
        "endLine": 113,
        "endChar": 16
      },
      "revId": "8a1a925df1d6b5754a35e6a6a19c255ce2b89991",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "1f9e8ce7_b9eeba2f",
        "filename": "internal/ceres/cuda_buffer.h",
        "patchSetId": 2
      },
      "lineNbr": 113,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-14T03:00:52Z",
      "side": 1,
      "message": "this is an issue worth thinking through now that we have some experience with it. please give it some thought and come up with a consistent design.\n\nwe are having to give similar thought to enabling threading in matrix vector products and there we have to pass both the context and number of threads to use.",
      "parentUuid": "ef021648_911e34f9",
      "range": {
        "startLine": 113,
        "startChar": 7,
        "endLine": 113,
        "endChar": 16
      },
      "revId": "8a1a925df1d6b5754a35e6a6a19c255ce2b89991",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "c2ed599f_04a25aa5",
        "filename": "internal/ceres/cuda_buffer.h",
        "patchSetId": 2
      },
      "lineNbr": 113,
      "author": {
        "id": 5135
      },
      "writtenOn": "2022-09-16T20:39:39Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "1f9e8ce7_b9eeba2f",
      "range": {
        "startLine": 113,
        "startChar": 7,
        "endLine": 113,
        "endChar": 16
      },
      "revId": "8a1a925df1d6b5754a35e6a6a19c255ce2b89991",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "765120c1_6b29bae9",
        "filename": "internal/ceres/cuda_buffer.h",
        "patchSetId": 2
      },
      "lineNbr": 117,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-14T08:25:49Z",
      "side": 1,
      "message": "I think it might be better to replace those two calls with\na. Scheduling cudaMemcpyAsync in the stream (so it will be run automatically once the previous operation finishes).\nb. Synchronizing after with cudaStreamSynchronize\n\nThis way behavior will be the same for both options of default stream operation, but we will synchronize one time less",
      "range": {
        "startLine": 115,
        "startChar": 4,
        "endLine": 117,
        "endChar": 26
      },
      "revId": "8a1a925df1d6b5754a35e6a6a19c255ce2b89991",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "5d0f9e20_394178f1",
        "filename": "internal/ceres/cuda_buffer.h",
        "patchSetId": 2
      },
      "lineNbr": 117,
      "author": {
        "id": 5135
      },
      "writtenOn": "2022-09-16T20:39:39Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "765120c1_6b29bae9",
      "range": {
        "startLine": 115,
        "startChar": 4,
        "endLine": 117,
        "endChar": 26
      },
      "revId": "8a1a925df1d6b5754a35e6a6a19c255ce2b89991",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "316055ec_0041a4df",
        "filename": "internal/ceres/dense_cholesky.cc",
        "patchSetId": 2
      },
      "lineNbr": 391,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-14T02:24:58Z",
      "side": 1,
      "message": "so stream synchronization is enough? whatever happened to the calls to devicesynchronize?",
      "revId": "8a1a925df1d6b5754a35e6a6a19c255ce2b89991",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "4951e6a5_74f88906",
        "filename": "internal/ceres/dense_cholesky.cc",
        "patchSetId": 2
      },
      "lineNbr": 391,
      "author": {
        "id": 5135
      },
      "writtenOn": "2022-09-14T02:42:51Z",
      "side": 1,
      "message": "The devicesync is a holdover from when not all operations were explicitly on a stream. Now that we have all ceres operations on one stream we can just sync on the stream. This has the advantage that it does not interfere with other GPU stuff that the host process may be doing on the same device.",
      "parentUuid": "316055ec_0041a4df",
      "revId": "8a1a925df1d6b5754a35e6a6a19c255ce2b89991",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    }
  ]
}