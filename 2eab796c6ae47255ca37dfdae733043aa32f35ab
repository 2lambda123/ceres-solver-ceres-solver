{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "5899b5ef_d996085d",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-08T11:38:48Z",
      "side": 1,
      "message": "The first part of bringing multi-threading to iterative linear solvers with partitioned matrix view and block-sparse matrices.\n\nThis provides a reasonable speedup for right products.\nWith higher core-counts ratio w.r.t GPGPU approach is close to memory throughput ratio (120GB/s vs 620GB/s in my setup).\n\nNote that a parallel-for implementation with non-interleaving indexes *is a must* to obtain good speedups; with interleaved indexes in ParallelFor performance gains are minuscule.",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "f5a9331d_e94fc505",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5010
      },
      "writtenOn": "2022-09-08T15:04:34Z",
      "side": 1,
      "message": "Thank you Dmitriy, this is very interesting. \nGiven that we are still going through figuring out which threadpool to use, I think we should review and submit this CL and use this as part of the evaluation of your change to the threadpool and what Mike is proposing.\n\nWDYT?",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "203496d3_184066c3",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5010
      },
      "writtenOn": "2022-09-08T15:06:21Z",
      "side": 1,
      "message": "I will review the CL later today. I also have another change which may impact this CL in flight https://ceres-solver-review.googlesource.com/c/ceres-solver/+/22760.",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "cf8d9069_8cb294d5",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-08T15:40:24Z",
      "side": 1,
      "message": "I think we can review and submit this one first; as long as callers do not provide a valid ContextImpl -- it should work as good as it was with sequential methods.\nThose changes do not depend on particular threadpool implementation per se, but only work great with those that do not supply nearby indices to different threads (for example, I had success with tbb-based one as I\u0027ve mentioned in google groups a while ago).\n\nSo far I\u0027ve only added setting parallel context into tests.\nI think it makes sense to get both left- and right- products multi-threaded before implementing setting parallel context in all iterative solvers.",
      "parentUuid": "f5a9331d_e94fc505",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "694b2f9b_17ddf9ea",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-08T15:40:24Z",
      "side": 1,
      "message": "I am ready to rebase over those changes if it will be easier this way.",
      "parentUuid": "203496d3_184066c3",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "1a2b02d5_8b29fae4",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5010
      },
      "writtenOn": "2022-09-08T15:43:02Z",
      "side": 1,
      "message": "I am still waiting on a review of my other change. But thats okay, I will take a detailed look at yours later today. My day is a bit bushed, but I should have time later in the evening today.",
      "parentUuid": "694b2f9b_17ddf9ea",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "1e40021e_abcd9037",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-08T21:32:55Z",
      "side": 1,
      "message": "I have some minor comments but one big one.\n\nThat has to do with SetContext and SetNumThreads.\n\nFirst of all, having two different methods means that you can call SetNumThreads while Context is null, which leaves you in a weird state.\n\nBut this raises the question, why should matrices have any thread and context objects at all.  \n\nI think the right thing to do is have the left and right multiply methods have threaded variants. WDYT?",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "9a5e588d_95b7b816",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-09T09:22:22Z",
      "side": 1,
      "message": "My decision to make matrices hold a pointer to ContextImpl object inside was mainly driven by CudaSparseMatrix storing a pointer to ContextImpl.\n\nThis definitely can be also implemented by passing a context object only to methods that utilize it, since not every method requires it.\n\nIf I change implementation for cpu-side matrices to accepting pointers to context only in methods that utilize it - should gpu-side matrix classes be changed in the same way?",
      "parentUuid": "1e40021e_abcd9037",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2d2a7bf1_349f87ab",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-11T14:49:27Z",
      "side": 1,
      "message": "Thats a good point, I had not thought about CudaSparseMatrix. In light of that decision it makes sense to have the Context in the matrix. Then the only thing that remains is the right way to inject the Context into the matrix and set the number of threads.\n\nShould this be a construction time thing, or should it be something that happens afterwards. Both of them have their ups and downs.\n\nI think the former is better, because once constructed the user does not have to worry about whether the matrix has the requisite capabilities or not. This may require that we have to pipe the context object more deeply in some places but I think if we if we allow injection of these objects later on, then it is not clear who is responsible for doing so.\n\nAnd to make sure that we are doing this right and not missing anything, I would not have constructors with default arguments and instead carefully modify all callsites.\n\nWDYT?",
      "parentUuid": "9a5e588d_95b7b816",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "52279d9d_ce3cf94f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-14T03:22:57Z",
      "side": 1,
      "message": "FYI",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "759ae621_3b3a4a6d",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5135
      },
      "writtenOn": "2022-09-14T12:08:42Z",
      "side": 1,
      "message": "In the Cuda* objects, the design I\u0027d like to move towards is that all objects get a ContextImpl* on construction, with the assumption that it has already been initialized. Constructors only perform a lightweight check to see if it is already initialized, and fail if not initialized. Since the context has all the handles that the CUDA operations need, all objects have consistent usage of resources.\n\nCan the number of threads be absorbed into the Context? If this needs to vary based on the compute being performed, it would be good to have something like a ThreadingPolicy under the context that returns (for example) the number of threads to use for different classes of operations.",
      "parentUuid": "2d2a7bf1_349f87ab",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "0ee3f8ba_0e1cf62e",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5135
      },
      "writtenOn": "2022-09-14T12:08:42Z",
      "side": 1,
      "message": "Great to see threading in the CPU SpMV operations!\n@Dmitriy, could you please add the CPU and GPU model numbers to the commit message?",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "aed4cbc1_0b786ad2",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5010
      },
      "writtenOn": "2022-09-14T13:45:48Z",
      "side": 1,
      "message": "I think context and threading are qualitatively different things. Context is passed to the problem object and is basically state which is expensive to carry, whereas num threads come from the solve call.\n\nI do not think they can or should be merged into one.\n\nSameer",
      "tag": "mailMessageId\u003d\u003cCAK0oyEoQ8dt0GjB6aURMm12DBj-5U2BOaa7kV+vc4LC9LdpMKQ@mail.gmail.com\u003e",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "0cf41311_e9fc0ea1",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5135
      },
      "writtenOn": "2022-09-14T13:54:32Z",
      "side": 1,
      "message": "Doesn\u0027t the context already manage the CXX thread pool? \nIs the plan to remove it from the context once the new threading model is implemented?",
      "parentUuid": "aed4cbc1_0b786ad2",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "9f4dd12c_b5e45dcf",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-14T13:56:41Z",
      "side": 1,
      "message": "It manages the thread pool, but it does not decide number of threads used to solve. The user can decide that independent of problem construction.",
      "tag": "mailMessageId\u003d\u003cCABqdRUD4\u003dQDqCM+\u003d4ePobT5p8PmnfpcvB5C8fUCfULv8mTV0+w@mail.gmail.com\u003e",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "28302ed7_893032f8",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-19T23:00:07Z",
      "side": 1,
      "message": "If we consider two of the options for clean API:\n - Passing context object and number of threads to constructor (and only to constructor, without option to modify later)\n - Passing context object and number of threads directly to operator functions (and avoiding storing it inside)\n\nIt now seems to me that the first one makes it a bit painful to use those objects (because you need to pass the context all the way down to all creation points).\n\nThus, at least for CPU matrices, it seems reasonable to provide context and number of threads at the place of invocation of SpMV products, decoupling storage from compute in a certain sense.\n\nThis will make APIs of GPU and CPU sparse matrices a bit diverged, but they already cannot be used interchangeably due to incompatible interfaces of right/left products.",
      "parentUuid": "759ae621_3b3a4a6d",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "ddf521ec_9feb627b",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-19T23:00:07Z",
      "side": 1,
      "message": "I will add CPU/GPU models to commit message with the next revision.\n\n\nAll timings were recorded on Supermicro 7049GP-TRT workstation with 2x Intel Xeon Platinum 8176 CPUs and 4x 2080Ti FE GPUs (2 GPUs per NUMA-node).\n\nSince there is no performance gain from running across NUMA-nodes, I limit execution and memory allocation to a single NUMA-node (and select GPU attached to that particular CPU using CUDA_VISIBLE_DEVICES environment variable).\n\n\nTheoretical maximal memory throughput for single CPU is 119Gbyte/s in six-channel configuration, and theoretical maximal memory throughput for GPU is 616Gbyte/s.\n\nBecause SpMV is bandwidth-limited, I would expect performance of CPU and GPU differ by a factor of ~5 on that machine.\n\n\nFor CRS matrices real speedup from GPGPU turns out to be 4.31/0.724\u003d5.95x (BA) 2.16/0.514\u003d4.2x (Unstructured), which matches the \"theory\" above reasonably good, in my opinion.\n\n\nIf you would like to reproduce those results on your machine - please keep in mind that certain modifications to ParallelFor routine are required (being discussed as a separate change-request).\n\n\nMy plan is to finish parallelization of parts \u0026 pieces required for iterative solvers on CPU first, and then provide GPU versions for partitioned matrices.",
      "parentUuid": "0ee3f8ba_0e1cf62e",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6f7ac646_e7f4cb6f",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-19T23:06:56Z",
      "side": 1,
      "message": "I am actually less concerned about consistency and I get the convenience argument.\nMy concern is that it makes the Matrix API ambiguous. Callers can never be sure if the matrix has its context and num threads have been set correctly or not. It might be fine, but as other people start working with the API, they will start sprinkling calls to SetContext and SetNumThreads over the code because they are not sure :/",
      "parentUuid": "28302ed7_893032f8",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "9f7ae28d_dee68218",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-19T23:06:56Z",
      "side": 1,
      "message": "Dmitriy, I am happy to do the API change to the SparseMatrix API if its too much yak shaving for you. ",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "e0ad6a13_acd78f06",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-21T08:44:05Z",
      "side": 1,
      "message": "It seems that we might need to go as high as LinearOperator.",
      "parentUuid": "9f7ae28d_dee68218",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "acc56000_9016f6c7",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-21T08:44:05Z",
      "side": 1,
      "message": "Ack",
      "parentUuid": "6f7ac646_e7f4cb6f",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e95ba6ed_5cef1aa7",
        "filename": "internal/ceres/block_sparse_matrix.cc",
        "patchSetId": 1
      },
      "lineNbr": 52,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-08T21:32:55Z",
      "side": 1,
      "message": "block -\u003e row_block_id",
      "range": {
        "startLine": 52,
        "startChar": 14,
        "endLine": 52,
        "endChar": 19
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "e8fe440e_7ba94287",
        "filename": "internal/ceres/block_sparse_matrix.cc",
        "patchSetId": 1
      },
      "lineNbr": 52,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-21T08:44:05Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "e95ba6ed_5cef1aa7",
      "range": {
        "startLine": 52,
        "startChar": 14,
        "endLine": 52,
        "endChar": 19
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "6e896051_951e3339",
        "filename": "internal/ceres/block_sparse_matrix.cc",
        "patchSetId": 1
      },
      "lineNbr": 55,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-08T21:32:55Z",
      "side": 1,
      "message": "all these ints can be marked const no?",
      "range": {
        "startLine": 55,
        "startChar": 6,
        "endLine": 55,
        "endChar": 19
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "a3e6509e_b29144eb",
        "filename": "internal/ceres/block_sparse_matrix.cc",
        "patchSetId": 1
      },
      "lineNbr": 55,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-21T08:44:05Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "6e896051_951e3339",
      "range": {
        "startLine": 55,
        "startChar": 6,
        "endLine": 55,
        "endChar": 19
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "4310c155_267ce9c1",
        "filename": "internal/ceres/block_sparse_matrix.cc",
        "patchSetId": 1
      },
      "lineNbr": 132,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-08T21:32:55Z",
      "side": 1,
      "message": "parallel for is perfectly capable of handling the 1 thread case, so why have two variants here?",
      "range": {
        "startLine": 132,
        "startChar": 4,
        "endLine": 132,
        "endChar": 15
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "90813c55_f2571ae0",
        "filename": "internal/ceres/block_sparse_matrix.cc",
        "patchSetId": 1
      },
      "lineNbr": 132,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-09T09:22:22Z",
      "side": 1,
      "message": "a. ParallelFor requires a valid context (maybe we can just move the check for context pointer lower inside ParallelFor implementation though).\n\n\nb. For small loops (which can be as small as computing 2x3 matrix by 3-vector product in the case of PartitionedMatrixView::RightMultiplyE) there is a very high penalty for wrapping loop body into std::function compared to \"perfect\" inlining of a local function (up to 15% for jacobians from BA problems, up to 5% for unstructured ones, ~5% for partitioned view).\nI\u0027ve tried to keep single-threaded performance unchanged.\n\n\nHere are timings with a separate single-threaded case with inlined loop body:\nRunning ./bin/spmv_benchmark\n----------------------------------------------------------------------\nBenchmark                                                         Time\n----------------------------------------------------------------------\nBM_BlockSparseRightMultiplyAndAccumulateBA/1_mean              28.2 ms\nBM_BlockSparseRightMultiplyAndAccumulateBA/1_median            28.2 ms\nBM_BlockSparseRightMultiplyAndAccumulateBA/1_stddev           0.186 ms\nBM_BlockSparseRightMultiplyAndAccumulateBA/1_cv                0.66 % \nBM_BlockSparseRightMultiplyAndAccumulateUnstructured/1_mean    24.4 ms\nBM_BlockSparseRightMultiplyAndAccumulateUnstructured/1_median  24.4 ms\nBM_BlockSparseRightMultiplyAndAccumulateUnstructured/1_stddev 0.225 ms\nBM_BlockSparseRightMultiplyAndAccumulateUnstructured/1_cv      0.92 % \nBM_CRSRightMultiplyAndAccumulateBA/1_mean                      23.8 ms\nBM_CRSRightMultiplyAndAccumulateBA/1_median                    23.8 ms\nBM_CRSRightMultiplyAndAccumulateBA/1_stddev                   0.053 ms\nBM_CRSRightMultiplyAndAccumulateBA/1_cv                        0.22 % \nBM_CRSRightMultiplyAndAccumulateUnstructured/1_mean            20.6 ms\nBM_CRSRightMultiplyAndAccumulateUnstructured/1_median          20.6 ms\nBM_CRSRightMultiplyAndAccumulateUnstructured/1_stddev         0.093 ms\nBM_CRSRightMultiplyAndAccumulateUnstructured/1_cv              0.45 % \n\nRunning ./bin/partitioned_matrix_view_benchmark\n----------------------------------------------------------------------\nBenchmark                                                        Time \n----------------------------------------------------------------------\nBM_PatitionedViewRightMultiplyAndAccumulateE_Static/1_mean     18.3 ms \nBM_PatitionedViewRightMultiplyAndAccumulateE_Static/1_median   18.4 ms \nBM_PatitionedViewRightMultiplyAndAccumulateE_Static/1_stddev  0.039 ms \nBM_PatitionedViewRightMultiplyAndAccumulateE_Static/1_cv       0.21 %  \nBM_PatitionedViewRightMultiplyAndAccumulateF_Static/1_mean     18.9 ms \nBM_PatitionedViewRightMultiplyAndAccumulateF_Static/1_median   18.9 ms \nBM_PatitionedViewRightMultiplyAndAccumulateF_Static/1_stddev  0.150 ms \nBM_PatitionedViewRightMultiplyAndAccumulateF_Static/1_cv       0.79 % \n\nHere are timings with single-threaded case being handled with ParallelFor:\n----------------------------------------------------------------------\nBenchmark                                                         Time\n----------------------------------------------------------------------\nBM_BlockSparseRightMultiplyAndAccumulateBA/1_mean              31.9 ms\nBM_BlockSparseRightMultiplyAndAccumulateBA/1_median            31.9 ms\nBM_BlockSparseRightMultiplyAndAccumulateBA/1_stddev           0.211 ms\nBM_BlockSparseRightMultiplyAndAccumulateBA/1_cv                0.66 % \nBM_BlockSparseRightMultiplyAndAccumulateUnstructured/1_mean    24.9 ms\nBM_BlockSparseRightMultiplyAndAccumulateUnstructured/1_median  24.8 ms\nBM_BlockSparseRightMultiplyAndAccumulateUnstructured/1_stddev 0.147 ms\nBM_BlockSparseRightMultiplyAndAccumulateUnstructured/1_cv      0.59 % \nBM_CRSRightMultiplyAndAccumulateBA/1_mean                      27.2 ms\nBM_CRSRightMultiplyAndAccumulateBA/1_median                    27.1 ms\nBM_CRSRightMultiplyAndAccumulateBA/1_stddev                   0.207 ms\nBM_CRSRightMultiplyAndAccumulateBA/1_cv                        0.76 % \nBM_CRSRightMultiplyAndAccumulateUnstructured/1_mean            22.0 ms\nBM_CRSRightMultiplyAndAccumulateUnstructured/1_median          22.0 ms\nBM_CRSRightMultiplyAndAccumulateUnstructured/1_stddev         0.063 ms\nBM_CRSRightMultiplyAndAccumulateUnstructured/1_cv              0.29 % \n\nRunning ./bin/partitioned_matrix_view_benchmark\n----------------------------------------------------------------------\nBenchmark                                                        Time \n----------------------------------------------------------------------\nBM_PatitionedViewRightMultiplyAndAccumulateE_Static/1_mean    19.5 ms \nBM_PatitionedViewRightMultiplyAndAccumulateE_Static/1_median  19.5 ms \nBM_PatitionedViewRightMultiplyAndAccumulateE_Static/1_stddev 0.068 ms \nBM_PatitionedViewRightMultiplyAndAccumulateE_Static/1_cv      0.35 %  \nBM_PatitionedViewRightMultiplyAndAccumulateF_Static/1_mean    19.8 ms \nBM_PatitionedViewRightMultiplyAndAccumulateF_Static/1_median  19.7 ms \nBM_PatitionedViewRightMultiplyAndAccumulateF_Static/1_stddev 0.153 ms \nBM_PatitionedViewRightMultiplyAndAccumulateF_Static/1_cv      0.78 %  \n\n\nAs one may note, there is always a [statistically] significant difference in favor of inlined loop body, while standard deviations are pretty small.",
      "parentUuid": "4310c155_267ce9c1",
      "range": {
        "startLine": 132,
        "startChar": 4,
        "endLine": 132,
        "endChar": 15
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "e34cd8b2_cd57e624",
        "filename": "internal/ceres/block_sparse_matrix.cc",
        "patchSetId": 1
      },
      "lineNbr": 132,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-11T14:49:27Z",
      "side": 1,
      "message": "thank you Dmitriy for these experiments make sense to me. I imagine having a lambda defined right where the parallelfor loop is used is not going to make things any better either. This is what is done elsewhere where we use parallelfor and this maybe worthy of some inspection in light of your experiments.",
      "parentUuid": "90813c55_f2571ae0",
      "range": {
        "startLine": 132,
        "startChar": 4,
        "endLine": 132,
        "endChar": 15
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "b516f1df_a71a9c23",
        "filename": "internal/ceres/block_sparse_matrix.cc",
        "patchSetId": 1
      },
      "lineNbr": 132,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-19T23:00:07Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "e34cd8b2_cd57e624",
      "range": {
        "startLine": 132,
        "startChar": 4,
        "endLine": 132,
        "endChar": 15
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ddf3e773_2f2fb905",
        "filename": "internal/ceres/block_sparse_matrix.h",
        "patchSetId": 1
      },
      "lineNbr": 141,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-08T21:32:55Z",
      "side": 1,
      "message": "drop blank",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "8d9197cf_b6b43cd6",
        "filename": "internal/ceres/block_sparse_matrix.h",
        "patchSetId": 1
      },
      "lineNbr": 141,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-21T08:44:05Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "ddf3e773_2f2fb905",
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8d6bd44f_20306f57",
        "filename": "internal/ceres/block_sparse_matrix.h",
        "patchSetId": 1
      },
      "lineNbr": 143,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-08T21:32:55Z",
      "side": 1,
      "message": "The default number of threads should be 1 no? what does zero mean?",
      "range": {
        "startLine": 143,
        "startChar": 22,
        "endLine": 143,
        "endChar": 23
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "1f9fda76_1ad1eb4a",
        "filename": "internal/ceres/block_sparse_matrix.h",
        "patchSetId": 1
      },
      "lineNbr": 143,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-21T08:44:05Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "8d6bd44f_20306f57",
      "range": {
        "startLine": 143,
        "startChar": 22,
        "endLine": 143,
        "endChar": 23
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "a7e1b3ed_be2934c9",
        "filename": "internal/ceres/compressed_row_sparse_matrix.cc",
        "patchSetId": 1
      },
      "lineNbr": 316,
      "author": {
        "id": 5002
      },
      "writtenOn": "2022-09-08T21:32:55Z",
      "side": 1,
      "message": "same comment as block_sparse_matrix.",
      "range": {
        "startLine": 316,
        "startChar": 6,
        "endLine": 316,
        "endChar": 19
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "5f4394c3_3c63725e",
        "filename": "internal/ceres/compressed_row_sparse_matrix.cc",
        "patchSetId": 1
      },
      "lineNbr": 316,
      "author": {
        "id": 6141
      },
      "writtenOn": "2022-09-29T09:42:37Z",
      "side": 1,
      "message": "Done (I suppose the comment was about a separate single-threaded loop)",
      "parentUuid": "a7e1b3ed_be2934c9",
      "range": {
        "startLine": 316,
        "startChar": 6,
        "endLine": 316,
        "endChar": 19
      },
      "revId": "2eab796c6ae47255ca37dfdae733043aa32f35ab",
      "serverId": "cdcfcfbe-2044-3b1f-b5d4-da77ad542329"
    }
  ]
}